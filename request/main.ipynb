{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping API from _techinasia.com/jobs_\n",
    "\n",
    "## Tools & Library: Python, Postman, Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** This scraping no purpose for sale at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inisialisasi Library\n",
    "**requests**: untuk melakukan request HTTP/S\n",
    "\n",
    "**pandas**: mengatur data dari raw .json\n",
    "\n",
    "**json**: menyimpan raw .json dari response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inisialisasi URL, Payload, dan Headers untuk keperluan request.\n",
    "**url**: URL dari API yang ingin di ambil datanya\n",
    "\n",
    "**payload**: merupakan body yang dikirim saat melakukan request, isi dari body terdapat parameter untuk mengambil data secara spesifik, seperti pekerjaan apa yang dicari, seberapa banyak data tersebut, pekerjaan dari kota mana yang ingin diambil, dan banyak lainnya.\n",
    "\n",
    "Maksimal dari request ini adalah 999/1000 data, lebih dari itu tidak terpanggil lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://219wx3mpv4-dsn.algolia.net/1/indexes/*/queries?x-algolia-agent=Algolia%20for%20vanilla%20JavaScript%203.30.0%3BJS%20Helper%202.26.1&x-algolia-application-id=219WX3MPV4&x-algolia-api-key=b528008a75dc1c4402bfe0d8db8b3f8e\"\n",
    "\n",
    "payload = \"{\\r\\n    \\\"requests\\\": [\\r\\n        {\\r\\n            \\\"indexName\\\": \\\"job_postings\\\",\\r\\n            \\\"params\\\": \\\"query=data&hitsPerPage=1000&maxValuesPerFacet=1000&page=0&facets=%5B%22*%22%2C%22city.work_country_name%22%2C%22position.name%22%2C%22industries.vertical_name%22%2C%22experience%22%2C%22job_type.name%22%2C%22is_salary_visible%22%2C%22has_equity%22%2C%22currency.currency_code%22%2C%22salary_min%22%2C%22taxonomies.slug%22%5D&tagFilters=&facetFilters=%5B%5B%22city.work_country_name%3AIndonesia%22%5D%5D\\\"\\r\\n        }\\r\\n    ]\\r\\n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the payload above, there is the following code:\n",
    "\n",
    "``query=`` \n",
    "*This is used to enter the keywords of the job being searched for. Leave it blank if you want to see all data.*\n",
    "\n",
    "``hitsPerPage=1000&maxValuesPerFacet=1000`` \n",
    "*It is used to retrieve how much data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Melakukan request ke URL yang sudah di inisialisasi sebelumnya dan mengirimkan data sebagai payload.\n",
    "\n",
    "``status_code``: Melakukan pengecekan apakah statusnya 200 (Berhasil)\n",
    "\n",
    "``raw``: Variabel untuk menampung raw data dari response\n",
    "\n",
    "Disini saya menyimpan `raw` data tersebut sebagai json sebelum di lakukan penyaringan maupun manipulasi tipe data, dengan sedikit memberi indent untuk dapat dibaca dengan baik. Karena jika tidak diberi indent, datanya susah untuk di baca.\n",
    "\n",
    "Dan, saya melakukan pengecekan, apabila statusnya tidak `200 (Tidak berhasil)`, maka tidak perlu di lanjutkan kode setelahnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Melakukan request\n",
    "# Kenapa post?\n",
    "# Techinasia sepertinya menggunakan GraphQL sehingga saat melakukan request metodenya POST\n",
    "response = requests.request(\"POST\", url, data=payload)\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Variabel `raw` sebagi penampungan response\n",
    "    raw = json.loads(response.text)\n",
    "\n",
    "    # Menyipan `raw` file\n",
    "    with open('raw.json', 'w') as r:\n",
    "        r.write(json.dumps(raw, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mengolah `raw` data\n",
    "\n",
    "Karena response tersebut berupa `.json`, maka disini saya menggunakan `looping` untuk melakukan penyaringan data kemudian di masukan ke dalam variabel `jobs` yang telah di inisialisasikan sebelumnya. Saya hanya akan mengambil beberapa `key` saja; `Judul pekerjaan, tipe pekerjaan, nama perusahaan, industri perusahaan, kota perusahaan, negara perusahaan, rata-rata - minimal dan maksimal gaji, pengalaman (minimal dan maksimal), keterampilan, dan tanggal listing tersebut di posting.`\n",
    "\n",
    "Dan, saya akan melakukan pengubahan tipe data pada `publised`, dimana awalnya berupa `string`, kemudian di covert ke `datatime` lalu di ambil hanya tanggalnya saja. Untuk bagian `salary avg, salary min, salary max` juga dilakukan perubahan data, dilakukan untuk memudahkan pengolahan selanjutnya oleh pengguna data ini nantinya, dimana apabila `salary` tersebut kosong, dari `raw data` akan memberikan value `0`, maka perlu perubahan menjadi `NaN` dengan bantuan `NumPy`.\n",
    "\n",
    "Jika Anda lihat pada kode dibawah ada `if salary > 100` itu karena terkadang ada job list yang salarynya hanya menulis `1, 10` dan sebagainya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi List untuk menampung hasil looping\n",
    "jobs = []\n",
    "\n",
    "for item in raw['results'][0]['hits']:\n",
    "    \n",
    "    # Looping untuk menjadikan 'job_skills' sebagai List, agar memudahkan saat membaca maupun mengolahnya\n",
    "    skills = [i['name'] for i in item['job_skills']]\n",
    "\n",
    "    # Convert 'Published' menjadi tipe data `date`\n",
    "    dt = datetime.strptime(item['published_at'], \"%Y-%m-%d %H:%M:%S\")\n",
    "    published = dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Inisialisasi variabel salary untuk memfilter data yang ngasal\n",
    "    salary = item['salary_avg']\n",
    "    \n",
    "    if salary > 100:\n",
    "        min_salary = item['salary_min']\n",
    "        max_salary = item['salary_max']\n",
    "        salary = salary\n",
    "    else:\n",
    "        min_salary = np.nan\n",
    "        max_salary = np.nan\n",
    "        salary = np.nan\n",
    "\n",
    "    # Mengatur kolom untuk DataFrame\n",
    "    job = {\n",
    "            'Title': item['title'],\n",
    "            'Job Type': item['job_type']['name'],\n",
    "            'Company Name': item['company']['name'],\n",
    "            'Company Industry': item['industries'][0]['name'],\n",
    "            'Company City': item['city']['name'],\n",
    "            'Company Country': item['city']['country_name'],\n",
    "            'Salary Avg': salary,\n",
    "            'Salary Min': min_salary,\n",
    "            'Salary Max': max_salary,\n",
    "            'Experience': item['experience'],\n",
    "            'Min Experience': item['experience_min'],\n",
    "            'Max Experience': item['experience_max'],\n",
    "            'Skills': skills,\n",
    "            'Published': published\n",
    "        }\n",
    "    # Memasukan hasil filter ke dalam List `jobs`\n",
    "    jobs.append(job)\n",
    "\n",
    "# Menjadikan List tersebut sebagai DataFrame, agar lebih mudah di olah\n",
    "# Juga, lebih mudah di lakukan export, seperti .csv, .json\n",
    "df = pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Menyimpan data ke .json\n",
    "\n",
    "Disini saya akan menjadikan 2 tipe `orient` untuk `.json`nya, hasilnya dapat dilihat pada masing-masing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data_table.json', orient='table')\n",
    "df.to_json('data_index.json', orient='index')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
